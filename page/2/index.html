<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;frankmartinem.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Muse&quot;,&quot;version&quot;:&quot;8.3.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;Searching...&quot;,&quot;empty&quot;:&quot;We didn&#39;t find any results for the search: ${query}&quot;,&quot;hits_time&quot;:&quot;${hits} results found in ${time} ms&quot;,&quot;hits&quot;:&quot;${hits} results found&quot;}}</script>
<meta name="description" content="Stay Hungry, Stay Foolish">
<meta property="og:type" content="website">
<meta property="og:title" content="FrankMartinem Blog">
<meta property="og:url" content="http://frankmartinem.github.io/page/2/index.html">
<meta property="og:site_name" content="FrankMartinem Blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Frank">
<meta property="article:tag" content="Neural Network, Computer Science">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://frankmartinem.github.io/page/2/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;en&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;page&#x2F;2&#x2F;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>FrankMartinem Blog</title><script src="/js/config.js"></script>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">FrankMartinem Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Learning & Studying</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Frank"
      src="/images/portrait.jpg">
  <p class="site-author-name" itemprop="name">Frank</p>
  <div class="site-description" itemprop="description">Stay Hungry, Stay Foolish</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">13</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">28</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>
  <div class="sidebar-button site-overview-item animated"><i class="fa fa-comment"></i>
    Chat
  </a>
  </div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/FrankMartinet" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;FrankMartinet" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:frankmartinet@163.com" title="E-Mail → mailto:frankmartinet@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Frankgoogle?spm=1010.2135.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Frankgoogle?spm&#x3D;1010.2135.3001.5343" rel="noopener" target="_blank"><i class="fab fa-csdn fa-fw"></i>CSDN</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Unscented-Kalman-Filter/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Unscented-Kalman-Filter/" class="post-title-link" itemprop="url">Unscented Kalman Filter</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-21 14:10:25" itemprop="dateCreated datePublished" datetime="2020-01-21T14:10:25+08:00">2020-01-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-03-20 14:18:16" itemprop="dateModified" datetime="2020-03-20T14:18:16+08:00">2020-03-20</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="Unscented-Kalman-Filter"><a href="#Unscented-Kalman-Filter" class="headerlink" title="Unscented Kalman Filter"></a>Unscented Kalman Filter</h4><p>最近读了一篇文献，里面用到了无迹卡尔曼滤波(Unscented Kalman Filter)。这里写一下我对这种方法的理解。卡尔曼滤波的理解部分可以参考</p>
<h5 id="我的一点点理解"><a href="#我的一点点理解" class="headerlink" title="我的一点点理解"></a>我的一点点理解</h5><p>无迹卡尔曼滤波是对卡尔曼滤波的一种改进。这种改进主要是针对非线性的信号。因为在卡尔曼滤波中，预测模型以及测量空间对应的转换矩阵都是都是线性转换。但是在面对非线性信号时，会出现无法拟合的情况。所以就有了无极卡尔曼滤波。这种方法的主要改进在于，不再用线性的模型去计算预测模型以及转换矩阵，而是通过采样和计算均值方法的方式，去估计样本的方差和均值。</p>
<h5 id="计算过程"><a href="#计算过程" class="headerlink" title="计算过程"></a>计算过程</h5><p>无迹卡尔曼滤波的计算方式和卡尔曼滤波比较类似，只是讲线性转换模型换成了采样的方式。具体的原理推导比较复杂，所以这里只写一下无迹卡尔曼滤波的计算过程：</p>
<p>无迹卡尔曼的计算步骤和卡尔曼滤波基本是一致的，只是对其中的一些步骤进行了修改，首先，我们看一下Kalman Filter的计算过程：</p>
<ol>
<li><p>建立编码模型和转换模型， 假设观测变量是$z$， 测量变量是$x$， 那么首先我们假设：</p>
<ol>
<li>当前时刻的测量变量是可以根据上一时刻的测量变量估计：<br>$$<br>x_{t} = Fx_{t-1} + w_t, (w_t -N(0, Q))<br>$$</li>
</ol>
</li>
<li><p>当前时刻的观测变量可以根据测量变量估计：<br>   $$<br>   z_t = Hx_t + r_t, (r_t - N(0, R))<br>   $$</p>
</li>
<li><p>根据以上的编码模型和转换模型，Kalman Filter的计算流程如下：</p>
<ol>
<li>首先，根据已知的模型，以及上一时刻的卡尔曼估计值，计算当前时刻的模型预测值</li>
</ol>
<p>$$<br>x_t’=Fx_{t-1}<br>$$</p>
<ol start="2">
<li>根据当前的模型预测值，计算对应的协方差</li>
</ol>
<p>$$<br>P(x_t|x_t’)=FP(x_t|X_t)F^T<br>$$</p>
<ol start="3">
<li>根据当前的协方差和测量空间的转换矩阵，计算当前时刻的卡尔曼增益</li>
</ol>
<p>$$<br>K_t=P(x_t|x_t’)H^T(HP(x_t|x_t’)H^T+R)^{-1}<br>$$</p>
<ol start="4">
<li>根据卡尔曼增益和测量值，计算当前时刻的卡尔曼估计值</li>
</ol>
<p>$$<br>x_t=x_t’+K_t(z_t-Hx_t’)<br>$$</p>
<ol start="5">
<li>计算了当前时刻的卡尔曼估计值之后，还需要计算当前的估计值和真实值的协方差矩阵，方便下一次计算</li>
</ol>
<p>$$<br>P(x_t|X_t)=(I-HK_t)P(x_t|x_t’)<br>$$</p>
<p>作为线性的解码器，Kalman Filter确实能找到观测变量和测量变量之间的关系，并用观测变量去纠正当前测量变量中的误差。但是涉及到非线性关系的时候，Kalman Filter的线性假设就不成立了。这时有两种优化的方法：</p>
<ol>
<li>如果已知这种非线性关系的公式，例如加速度和位置的关系等，那么可以把上述转换模型和观测模型换成已知的非线性模型，增加解码准确率。这种方法就是**扩展卡尔曼滤波(Extend Kalman Filter)**。这种方法的优点在于拟合更加准确，但是缺点也很明显。首先是计算量增加，如果非线性拟合涉及很复杂的模型，那么计算量比Kalman Filter增加很多。然后是非线性模型，并不是任何时候，这种模型都是已知的，如果不是已知的，那就需要进行非线性拟合，找到最合适的拟合模型，例如指数模型，高阶模型等，再次增加计算量。</li>
<li>如果不知道这种非线性关系的公式，那么我们可以进行非线性拟合或者直接假设一个公式。但是我们观察Kalman Filter的计算过程，整个估计过程中，用到了当前时刻的值，以及协方差。而这两个量，我们是能通过采样的方式得到的，即，可以不需要直接计算非线性模型的协方差矩阵，直接通过采样估计，类似蒙特卡洛的方法。但是采样的计算量会更大，因为需要大样本才能得到准确的估计。目前有另外一种办法，能够用很少的采样点(几个)就得到准确的估计，这种方法是无迹变换(Unscented Transform)，结合到Kalman Filter中，就是<strong>无迹卡尔曼滤波(Unscented Kalman Filter)</strong></li>
</ol>
<p>所以无迹卡尔曼滤波的主要流程如下：</p>
<ol>
<li>计算转换模型和编码模型<ol>
<li>建立转换模型，可以是非线性也可以是线性，这里用线性模型：<br>$$<br>x_{t} = Fx_{t-1} + w_t, (w_t -N(0, Q))<br>$$</li>
<li>建立编码模型，也可以是线性或非线性模型：<br>$$<br>z_t = Hx_t + r_t, (r_t - N(0, R))<br>$$</li>
</ol>
</li>
</ol>
</li>
<li><p>根据上述模型和训练集数据，用最小二乘法或其他的拟合方法，得到模型参数，然后开始无迹卡尔曼的预测和更新阶段</p>
<ol>
<li><p>根据模型预测$x_{t}$<br>   $$<br>   x_t’=Fx_{t-1}<br>   $$</p>
</li>
<li><p>预测$x_{t}$的协方差<br>   $$<br>   P(x_t|x_t’)=FP(x_t|X_t)F^T + Q<br>   $$</p>
</li>
<li><p>用采样点估计当前协方差矩阵，先采样$2d+1$个点，并保证中心点的值为$x_t’$<br>   $$<br>   X_0 = x_t’<br>   $$</p>
<p>$$<br>   X_i = x_t’ + (\sqrt{(d + k)P(x_t|x_t’)})_{i}, i = 1, …, d<br>$$</p>
<p>$$<br>   X_i = x_t’ - (\sqrt{(d + k)P(x_t|x_t’)})_{i}, i = d + 1, …, 2d<br>$$</p>
</li>
<li><p>计算采样点的权重值<br>   $$<br>   w_0= \frac{k}{d+k}, w_i = \frac{1}{2d+k}, i = 1, … 2d<br>   $$</p>
</li>
<li><p>根据转换矩阵，采样点，计算观测值和测量值的关系<br>$$<br>Z_i = h(X_i), i = 0, …2d<br>$$</p>
<p>$$<br>z_t = \sum_{i = 0, …2d}{w_{i}Z_{i}}<br>$$</p>
</li>
<li><p>根据采样点估计的观测值，计算观测值$z$的方差，以及观测值$z$和测量值$x$的协方差<br>$$<br>P_{zz, t} = w_{0}(Z_{0}-z_{t})(Z_{0}-z_{t})^T + (\sum_{i=1, …,2d}{w_{i}(Z_{i}-Z_{0})(Z_{i}-z_{0})^T}) + R<br>$$</p>
<p>$$<br>P_{xz, t} = w_{0}(Z_{0}-z_{t})(Z_{0}-z_{t})^T + (\sum_{i=1, …, 2d}{w_{i}(X_{i}-X_{0})(Z_{i}-Z{0})^T})<br>$$</p>
</li>
<li><p>根据计算的协方差，可以计算Kalman增益<br>$$<br>K = P_{xz, t}P_{zz, t}^{-1}<br>$$</p>
</li>
<li><p>用Kalman增益计算最有估计值<br>$$<br>x_t = x_t’ + K_t(h(x_t’)-z_t)<br>$$</p>
<p>$$<br>P(x_t|X_t) = P(x_t|x_t’)-P_{xz, t}(P_{zz, t}^{-1})^TP_{xz, t}^{T}<br>$$</p>
<p>以上就是无迹卡尔曼滤波的主要步骤，后续会附上代码链接</p>
</li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Unity/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Unity/" class="post-title-link" itemprop="url">Unity</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-01-21 14:10:10 / Modified: 14:37:12" itemprop="dateCreated datePublished" datetime="2020-01-21T14:10:10+08:00">2020-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%96%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">编程</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Unity相关概念"><a href="#Unity相关概念" class="headerlink" title="Unity相关概念"></a>Unity相关概念</h3><ol>
<li><p>ConfigurableJoint</p>
</li>
<li><p>OnEnable()函数在gameObject.setActive(true)时触发，优先于Start()，但是和Awake()函数的先后顺序不确定；OnDisable()函数在gameObject.setActive(false)时触发</p>
</li>
<li><p>Lerp()</p>
<ol>
<li><p>计算两个点之间的插值，函数如下：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Lerp(Vector3 a, Vector3 b, <span class="built_in">float</span> t);</span><br></pre></td></tr></table></figure>

<p>计算公式如下：</p>
<p>$$ (b - a) * t $$</p>
</li>
</ol>
</li>
<li><p>Mathf.Approximately()</p>
<ol>
<li><p>判断两个浮点数是否十分接近，使用方法如下：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mathf.Approximately(<span class="built_in">float</span> a, <span class="built_in">float</span> b);</span><br></pre></td></tr></table></figure>

<p>返回值为bool</p>
</li>
</ol>
</li>
<li><p>Quaternion类</p>
<ol>
<li>Quaternion属于四元数，包括x, y, z, w四个分量，和欧拉角一样，是3D图形中常用的坐标变换表示方法之一，对于插值，平滑以及数据存储，都有较大的优势（相较于传统的矩阵表示方法）</li>
<li></li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Talk-Joe-Tsien/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Talk-Joe-Tsien/" class="post-title-link" itemprop="url">Talk Joe Tsien</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-01-21 14:10:03 / Modified: 14:35:34" itemprop="dateCreated datePublished" datetime="2020-01-21T14:10:03+08:00">2020-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E8%AE%B2%E5%BA%A7/" itemprop="url" rel="index"><span itemprop="name">讲座</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="破译大脑"><a href="#破译大脑" class="headerlink" title="破译大脑"></a>破译大脑</h3><ul>
<li>Cre-lox，NMDA受体</li>
<li>聪明鼠</li>
<li>One-shock Learning</li>
<li>Theory of Connectivity<ul>
<li>logic </li>
<li>anatomically prevalent</li>
<li>neuromodulationtory neurons use different logic</li>
<li>pre-configured by development</li>
<li>cross laminar layers</li>
<li>evolutionary conserved across species</li>
</ul>
</li>
<li>Brain Computation is Organized via power of two Based Permutation logic(Neuroal Frontiers)</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Two-Types-of-Variance/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Two-Types-of-Variance/" class="post-title-link" itemprop="url">Two Types of Variance</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-01-21 14:09:44 / Modified: 14:25:04" itemprop="dateCreated datePublished" datetime="2020-01-21T14:09:44+08:00">2020-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="样本方差和统计方差"><a href="#样本方差和统计方差" class="headerlink" title="样本方差和统计方差"></a>样本方差和统计方差</h3><p>我们知道，统计学上方差的计算公式如下：</p>
<p> $$ \sigma^2=\frac{\sum_{i=1}^{n}(x_i-\mu)}{n}$$ </p>
<p>这是统计学中方差的定义，已知条件有总体的均值$\mu$，以及总体个数$n$，公式的另一种写法为： $$\sigma^2=E[(x-\mu)^2]=\sum{(x-\mu)^2}p(x)$$ </p>
<p>其中$p(x)$是$x$出现的概率，所以这个公式只对于离散变量有效。 那么，如果总体量很大，不能做到全部采样，那么就需要用样本来估计总体，假设从总体为$N$的总数中抽取$n$个样本，其中$(N&gt;&gt;n)$，采样值为$x_1,x_2,…,x_n$ 样本均值为：</p>
<p> $$\bar{x}=\frac{\sum_{i=1}^{n}{x_i}}{n}$$ </p>
<p>样本的方差为：</p>
<p> $$ S^2=\frac{\sum_{i=1}^{n}(x_i-\bar{x})}{n}$$ </p>
<p>但是样本的方差和总体的方差是有差别的，计算样本方差的期望值，来估计样本方差和实际方差$\sigma^2$之间差了多少：</p>
<p> $$ E[S^2]=E[\frac{\sum_{i=1}^{n}(x_i-\bar{x})}{n}]$$ </p>
<p>$$=E[\frac{1}{n}\sum_{i=1}^{n}{((x_i-\mu)-(\bar{x}-\mu))^2}]$$</p>
<p>$$=E[\frac{1}{n}\sum_{i=1}^{n}{((x_i-\mu)^2-2(x_i-\mu)(\bar{x}-\mu)+(\bar{x}-\mu)^2)}]$$</p>
<p>$$=E[\frac{1}{n}\sum_{i=1}^{n}{(x_i-\mu)^2}-\frac{2}{n}(\bar{x}-\mu)\sum_{i=1}^{n}{(x_i-\mu)}+(\bar{x}-\mu)^2]$$ </p>
<p>其中</p>
<p> $\sum_{i=1}^{n}{(x_i-\mu)}$ $=\sum_{i=1}^{n}{x_i}-\sum_{i=1}^{n}{\mu}$ $=n(\bar{x}-\mu)$ </p>
<p>所以</p>
<p>$=E[\frac{1}{n}\sum_{i=1}^{n}{(x_i-\mu)^2}-\frac{2}{n}(\bar{x}-\mu)\sum_{i=1}^{n}{(x_i-\mu)}+(\bar{x}-\mu)^2]$ $=E[\frac{1}{n}\sum_{i=1}^{n}{(x_i-\mu)^2}-2(\bar{x}-\mu)^2+(\bar{x}-\mu)^2]$ $=\sigma^2-E[(\bar{x}-\mu)^2]$ </p>
<p>（这里$\sigma^2$是因为样本方差的期望值是总体方差）</p>
<p>$E[(\bar{x}-\mu)^2]$ $=E(\bar{x}-E[\bar{x}])^2$ $=var(\bar{x})$ $=\frac{1}{n^2}var(\sum_{i=1}^{n}{x_i})$ $=\frac{1}{n^2}\sum_{i=1}^{n}{var(x_i)}$ $=\frac{n\sigma^2}{n^2}$ $=\frac{\sigma^2}{n}$ </p>
<p>根据上面推导的式子，有以下计算：</p>
<p> $\sigma^2-E[(\bar{x}-\mu)^2]$ $=\sigma^2-\frac{\sigma^2}{n}$ $=\frac{n-1}{n}\sigma^2$ </p>
<p>也就是说，样本估计的方差是总体方差的$\frac{n-1}{n}$倍，即所谓的有偏估计。要转换成无偏估计，只需要乘以倍数就可以了 </p>
<p>$$\frac{n}{n-1}S^2=\frac{n}{n-1}\frac{\sum_{i=1}^{n}(x_i-\bar{x})}{n}=\frac{\sum_{i=1}^{n}(x_i-\bar{x})}{n-1}$$</p>
<p> 这即是所谓的无偏估计。 当然，还有一种比较直接的解释，由于是求统计样本中的方差，所以在求解统计样本均值时，已经用掉了一个自由度的值，所以求方差时，其实有用的值会少一个。例如在只有一个样本时，这时求方差是没有意义的。不过在概率论中，求此时的方差是有意义的，因为已经知道了总体的概率分布，所以即使只有一个样本，总体的分布是不变的。其中区别就在于统计样本只是用于估计。 </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Population-Vector-Algorithm/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Population-Vector-Algorithm/" class="post-title-link" itemprop="url">Population Vector Algorithm</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-21 14:09:04" itemprop="dateCreated datePublished" datetime="2020-01-21T14:09:04+08:00">2020-01-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-04-13 18:10:20" itemprop="dateModified" datetime="2020-04-13T18:10:20+08:00">2020-04-13</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="PVA-Population-Vector-Algorithm"><a href="#PVA-Population-Vector-Algorithm" class="headerlink" title="PVA(Population Vector Algorithm)"></a>PVA(Population Vector Algorithm)</h3><h4 id="算法推导："><a href="#算法推导：" class="headerlink" title="算法推导："></a>算法推导：</h4><ol>
<li><p>信号预处理 这里的算法推导主要针对神经元集群解码，因为PVA的主要应用还是在神经元解码中 首先，采集到的spike信号是以发放次数的方式存储的，这里需要先转换成发放率的形式，即： $$fr[n]=\frac{spk[n]}{\Delta t} \tag{1}$$</p>
</li>
<li><p>其中，$fr[n]$表示$n$时刻神经元的发放率，$\Delta t$表示一个bin的长度，通常的取值为20ms，30ms，50ms，1000ms等。$spk[n]$表示神经元在第$n$个bin中发放的次数。 然后，对发放率做一个FIR滤波，主要目的是平滑发放率曲线，计算公式如下：</p>
<p>$$s[n]=\sum_{i=1}^{W-1}{fr[n-i]h[i]} \tag{2}$$</p>
<p>其中，$h[i]$表示滤波器的卷积函数，可以根据需求选取，$W$表示滤波器的阶数，可以根据实际需要选择。</p>
<p>PVA算法原理 PVA算法的提出，主要是根据实验中观察到的现象。在猴子将手臂移动向不同的方向时，不同的神经元发放的率产生了变化，我们由此假设，神经元的发放率跟运动方向是有关系的，所以我们想到，用余弦曲线的方式，去拟合神经元的发放率与运动方向之间的关系。首先，我们假设每个神经元都有一个自己的偏好方向$\theta_{PD}$，假设此时，猴子手臂的运动方向为$\theta$，那么此时神经元的发放率为： $$f=m*cos(\theta-\theta_{PD})+b_0 \tag{3}$$ </p>
<p>其中，$m$为表征神经元活泼性的参数，即有的神经元可能表征的偏好方向一样，但是在偏好方向上的发放率变化是不一样的。$b_0$表示神经元的基础发放率，即在静息状态下的基础发放率。$f$表示的是神经元在猴子手臂朝向$\theta$方向运动时的发放率，注意这里是发放率不是spike count，虽然两者可以通过bin转换，但是公式推导的时候两者还是不一样的。 公式$(3)$表示了单个神经元的发放与运动的关系。猴子大脑M1区域的神经元是很多的，对不同的方向肯定有不同的偏好性。那么如何处理这种不一致性呢，我们的方法是用矢量求和的形式，得出一个此时最可能的运动方向。即： $$\vec{u}=\frac{1}{N}  \sum_{i=1}^{n}{m*cos{\theta_{PD}}} \tag{4}$$ </p>
<p>这里$\vec{u}$表示神经元此时解码出来的运动方向，这里也能部分表征运动速度，但是速度的大小也与实际的运动距离有关，所以，运动速度的计算如下：</p>
<p> $$v=k*\vec{u}+\sigma \tag{5}$$</p>
<p>这里$k$表示实际速度与计算得出的速度的比例，$\sigma$表示实际速度与解码得到的速度之间的误差，以上就是PVA算法的主要原理 3. 参数计算 那么，现在的问题在于，如何计算PVA算法中的几个参数，这里我们用最小二乘法的方式，求最小误差情况下的参数$b_0,m,\theta_{PD}$，我们将公式$(3)$换一种写法，即： </p>
<p>$$f = b_0 + b_1 * cos \theta + b_2 * sin \theta \tag{6}$$ </p>
<p>再考虑$cos{\theta}$和$sin{\theta}$这两个量，对应在速度中，可以表示为归一化过后的$v_x$和$v_y$，只要在$[-1,1]$这个区间内所以，将公式$(6)$写成： </p>
<p>$$f = b_0 + b_1 * v_x + b_2 * v_y \tag{7}$$</p>
<p>用最小二乘法计算，误差为： </p>
<p>$$\epsilon = \sum_{ i=1 }^{n}{(b_0 + b_1 * v_x + b_2 * v_y - f)^2} \tag{8}$$</p>
<p>最终计算结果根据要推导一下，这里先暂时不写，回去再补充 所以，极值在偏导数为$0$的地方取得，即： $$\frac{\partial{\epsilon}}{\partial{b_0}}=0 \tag{9}$$ $$\frac{\partial{\epsilon}}{\partial{b_1}}=0 \tag{10}$$ $$\frac{\partial{\epsilon}}{\partial{b_2}}=0 \tag{11}$$ </p>
<p>解上述方程，可以得到$b_0,b_1,b_2$的值，即：</p>
<p> $$\beta=(A^T*A)^{-1}A^TB \tag{12}$$ </p>
<p>其中，$\beta=(b_0,b_1,b_2)$，$A$为运动信息矩阵，$B$为神经信号矩阵。  </p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Hidden-Markov-Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Hidden-Markov-Model/" class="post-title-link" itemprop="url">Hidden Markov Model</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-21 14:08:45" itemprop="dateCreated datePublished" datetime="2020-01-21T14:08:45+08:00">2020-01-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-04-19 21:58:06" itemprop="dateModified" datetime="2020-04-19T21:58:06+08:00">2020-04-19</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="Hidden-Markov-Model"><a href="#Hidden-Markov-Model" class="headerlink" title="Hidden Markov Model"></a>Hidden Markov Model</h1><h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>隐马尔可夫模型(Hidden Markov Model)是一种常用的统计模型。应用也比较广泛，在时序问题，以及语音识别等问题上有广泛的应用。下面简单介绍一下隐马尔可夫模型。</p>
<p>隐马尔可夫模型是在马尔可夫过程的基础上，加入了隐含状态后的一种结构。这里首先介绍一下什么是马尔可夫过程(Markov Process)</p>
<p>在一个随机过程中，有一个状态变量$I$，其下一时刻的状态之和之前的状态有关。例如布朗运动，粒子的下一时刻状态之和之前时刻的状态有关。而$I$变化的过程，也就是马尔科夫链。这个约束，也就是马尔可夫假设。</p>
<p><img src="E:\GitHub-Blog\source\img\HiddenMarkovModel-1.jpg"></p>
<p>在马尔可夫过程中，模型还是很复杂，我们还可以加约束来让模型变得简单一点。我们可以假设，状态变量$I$的下一时刻状态只和上一时刻的状态有关。这样就得到了齐次马尔可夫模型。即：</p>
<p>$$p(I_t|I_{t-1}, I_{t-2}, …, I_{0}) = p(I_t|I_{t-1}), t=1, 2, …, T$$</p>
<p>我们可以看出，马尔可夫模型的描述，只针对某一个变量而言。但是实际生活中，很多变量之间都是相关的。例如你的运动是由肌肉的收缩和舒张来完成的。但是在观察者看来，你只是完成了一个简单的运动。其中，你的运动状态就是观测到的变化量，而肌肉的状态就是隐藏的状态。所以HMM模型的结构如下图所示：</p>
<p><img src="E:\GitHub-Blog\source\img\HiddenMarkovModel-2.jpg"></p>
<p>和马尔可夫过程一样，HMM也有一些约束条件。首先，HMM要满足马尔可夫假设且满足齐次马尔可夫模型，即：</p>
<p>$$p(I_t|I_{t-1}, o_{t-1}, …, I_{0}, o_{0}) = p(I_t|I_{t-1}), t=1, 2, …, T$$</p>
<p>然后是观测独立性假设，也就是说任意时刻的观测值只依赖于当前时刻的马尔可夫链的状态$i_t$， 即：</p>
<p>$$p(o_t|I_t, I_{t-1}, o_{t-1}, …, I_{0}, o_{0}) = p(o_t|I_t), t=1, 2, …, T$$</p>
<h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>HMM的结构如上图所示，其中$I$是状态变量，$O$是观测变量。假设$Q$是所有可能的状态的集合，$V$是所有可能的观测的集合。</p>
<p>$$Q = { q_1,q_2,…,q_N }$$ </p>
<p>$$V = {v_1,v_2,…,v_M }$$</p>
<p>即可能的状态有N种， 可能的观测值有M种，两者不一定会相等。那么在一次试验中，观测到的值为$O$，每个观测值会唯一对应一个状态值，因为试验已经结束了，假设状态序列为$I$，那么$O$和$I$的长度一样，假设为T，那么： $$O = { O_1,O_2,…,O_T }$$ </p>
<p>$$I = { I_1,I_2,…,I_T }$$</p>
<p> 在$t$时刻会有一个状态值，那么下一个时刻的状态值会与上一时刻相关，当然也可以是不相关的，由此给出状态矩阵$A$的定义：</p>
<p>$$A=[a_{ij}]$$ </p>
<p>$a_{ij}$表示当前时刻$t$状态为$q_i$的情况下，下一时刻的状态为$q_j$的概率，这里$i,j=1,2,…N$，用数学形式表示，即： $$a_{ij}=P(I_{t+1}=q_j | I_t=q_i)$$ </p>
<p>有了状态转移矩阵后，我们并不能直接估计下一时刻的状态，因为状态在整个试验过程中是隐藏的，试验中只能得到观测值的相关信息，所以还要有观测值和状态值之间的转换矩阵，即当观测到某个值时，其对应于各个状态的概率分别是多少。假设观测概率矩阵是$B$，给出$B$的定义：</p>
<p> $$B=[b_{jk}]$$ </p>
<p>$b_{jk}$表示当前时刻$t$状态值为$q_j$的情况下，观测值为$v_k$的概率。所以有$k=1,2,…M$，$j=1,2,…,N$，用数学形式表示，即：</p>
<p>$$b_{jk}=P(o_t=v_k | i_t=q_j)$$ </p>
<p>确定了观测值和状态值之间的转换概率，当前时刻和下一时刻之间的状态转换概率，那么我们还需要确定可能的观测值在试验刚开始时被选中的概率，假设为$\pi$，给出$\pi$的定义：</p>
<p>$$\pi=[\pi_{i}]$$ </p>
<p>其中$\pi_{i}$表示观测值$q_i$在刚开始被选中的概率，那么，$i=1,2,…,N$，用数学的形式表示，即：</p>
<p>$$\pi_i=P(I_1=q_i)$$ </p>
<p>到这里，整个HMM模型中的主要参数已经全部介绍了，由介绍可知，根据$\pi,A,B$可以让一个HMM模型顺利工作。可以求出在任意状态序列对应的概率$P(O|\lambda)$。所以，我们也用这些参数来表示一个HMM模型，即： $$\lambda={ A,B,\pi }$$ 。</p>
<h2 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h2><p>以上介绍了HMM的基本概念，在实际应用中，主要有以下几个基本问题：</p>
<ol>
<li>已知模型$\lambda$以及观测序列$O$，计算在这种模型下出现这种观测序列的概率$P(O|\lambda)$</li>
<li>已知观测序列$O$，但是不知道模型$\lambda$，计算模型$\lambda$，使得当前观测序列产生的概率$P(O|\lambda)$最大</li>
<li>给定模型$\lambda$和观测序列$O$，计算最有可能产生这一观测序列的状态序列$I$，即使得$P(I|O,\lambda)最大的$$I$</li>
</ol>
<p>以上就是最常见的HMM问题，主要涉及到模型中各个参数计算的问题。</p>
<p>在问题１中，我们需要计算观测序列出现的概率，主要可以用来判断出现的这一观测序列是否常见，如果计算得到的概率很低，但是在实际观测中却经常出现，那么就需要检查系统中是否出现了外部干扰。</p>
<p>在问题2中，我们需要计算模型的参数。主要是用于模型的学习和自适应参数调整的问题。模型是不确定的，但是根据给定的观测序列，我们需要找到一个最合适的模型，来保证出现这一观测序列的概率最大。有点类似回归求最优解或者神经网络拟合的思想。</p>
<p>在问题3中，我们需要通过观测序列和模型，来估计隐藏状态。这个主要适用于一些解码问题。通过观测值求解隐藏值。</p>
<p>针对以上的问题，分别有对应的解决办法。下面会介绍最常见的一些解法。当然，由于ＨＭＭ中，观测变量和隐藏状态可能的取值是有限的。所以其实用穷举法也可以算，只是计算量会很大。</p>
<h2 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h2><h3 id="问题1"><a href="#问题1" class="headerlink" title="问题1"></a>问题1</h3><p>已知模型和观测序列，要计算出现这种观测序列的概率$P(O|\lambda)$</p>
<p>这个问题有两种解法，前向和后向算法。两种方法比较类似。</p>
<ol>
<li>前向算法</li>
</ol>
<p>首先，我们定义一个概率：</p>
<p>$$p_t(i) = P(o_1, o_2, …, o_t, I_t=q_i)$$</p>
<p>$p_t(i)$表示观测序列为${o_0, o_1, …,o_t}$，同时$I_t=q_i$的概率。所以我们有以下递推公式：</p>
<p>$$p_{t}(i) = (\sum_{j=1}^{N}p_{t-1}(j)a_{ji})b_{ik}$$</p>
<p>同时，有$o_{t}=v_{k}$。在上面的公式中，$\sum_{j=0}^{N}p_{t-1}(j)a_{ji}$表示前$t-1$个输出为${o_1, o_2, …, o_{t-1}}$，且第$t$个隐藏状态为$q_i$的概率。因为$t-1$时刻的状态是任何值都可以，只需要乘以对应的转移概率，就可以计算出$t$时刻状态为$q_i$的概率了。</p>
<p>然后在初始状态时，有：</p>
<p>$$p_1(i) = \pi_ib_{ik}, o_1=v_k$$</p>
<p>所以最终得到的概率为：</p>
<p>$$P(O|\lambda) = \sum_{i=1}^{N}p_T(i)$$</p>
<p>也就是说，在$T$时刻，观测序列为${o_1, o_2, …, o_T}$，且模型为$\lambda$的概率为观测序列为${o_1, o_2, …, o_T}$且$T$时刻状态值为${q_1, q_2, …, q_N}$的所有值的和。</p>
<ol start="2">
<li>后向算法</li>
</ol>
<p>后向算法和前向算法比较类似，都是通过递推的方式逐步计算观测序列的概率。不同的地方是，后向算法是从后往前算，前向算法是从前往后算。</p>
<p>假设观测序列的长度为$T$，并定义从$t+1$时刻到$T$时刻的序列为${o_{t+1}, o_{t+2}, …, o_T}$，且$t$时刻的隐藏状态为$q_i$的概率为：</p>
<p>$$p_t(i) = P(o_{t+1}, o_{t+2}, …, o_T, I_t=q_i|\lambda)$$</p>
<p>对于后向算法，初始状态应该是$p_T(i)$，表示的是观测序列为${o_{T+1}}$时，且隐藏状态为$q_i$的概率，但是因为已经知道了$o_T$的状态了，且$o_{T+1}$并没有发生，所以这里其实给任意值都可以。这个值其实主要表示的是$T+1$时刻和$T$时刻的关系，但是这个关系并不知道，所以给任意值都是可以的。表示这个关系可以是任意的。</p>
<p>然后和前向算法类似，我们可以计算后向的递推公式：</p>
<p>$$p_t(i) = \sum_{j=1}^{N}a_{ij}b_{jk}p_{t+1}(j)$$</p>
<p>其中有，$o_{t+1} = v_k$</p>
<p> $\sum_{j=1}^{N}a_{ij}p_{t+1}(j)$表示$t+2$时刻状态为$q_j$且$t$时刻的状态为$q_i$的所有可能的$t+2$时刻的值的和，所以$a_{ij}b_{jk}p_{t+1}(j)$表示的是，$t+1$时刻的观测值为$o_{t+1}$，也就是$v_k$，同时$t+1$时刻的状态值为$q_j$的概率。求和之后就是，$t+1$到$T$时刻的观测值为${o_{t+1}, o_{t+2}, …, o_{T}}$，且$</p>
<p>t$时刻的隐藏状态为$$q_i$的概率。也就是$p_t(i)$。</p>
<p>所以可以得到，最终计算的概率为：</p>
<p>$$P(O|\lambda) = \sum_{i=1}^{N}\pi_{i}b_i(o_1)p_1(i)$$</p>
<p>其中，$p_1(i)$表示的是观测序列为${o_2, o_3, …, o_T}$，$ b_i(o_1)p_1(i)$表示观测序列为${o_1, o_2, …, o_T}$。所以$\pi_ib_i(o_i)p_1(i)$表示观测序列为$o_1, o_2, …, o_T$, 且$I_1=q_i$的概率，对所有的$I_1={q_1, q_2, …, q_N}$求和，就是观测序列为${o_1, o_2, …, o_N}$的概率</p>
<p>以上就是两种计算观测序列概率的算法。主要的思想都是通过递推计算。</p>
<h3 id="问题2"><a href="#问题2" class="headerlink" title="问题2"></a>问题2</h3><p>已知观测序列$O$， 计算使得$P(O|\lambda)$最大的模型参数$\lambda$</p>
<p>这个问题有点类似于回归问题中的拉格朗日极值问题，但是由于涉及到隐藏变量的极大似然估计，所以这里并不能用求导的方法来计算。广泛使用的一种计算方法是EM(Expectation Maximum)算法。关于EM算法，会在后续的文章中介绍，这里暂且不写。</p>
<h3 id="问题3"><a href="#问题3" class="headerlink" title="问题3"></a>问题3</h3><p>已知观测序列$O$和模型参数$\lambda$，求可能产生这一观测序列的隐藏状态$I$, 使得$P(I|\lambda)$最大</p>
<p>这个问题类似于常见的解码问题。对于HMM模型下的解码问题，一般是用动态规划的方法来求解的。因为这样计算量会降低。常用的HMM解码问题的解决办法是维特比算法(Viterbi Algorithm)。这个也会在后续的文章中介绍。这里暂且不写。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Dimensionality-Reduction/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Dimensionality-Reduction/" class="post-title-link" itemprop="url">Dimensionality Reduction</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-01-21 14:08:27 / Modified: 15:28:46" itemprop="dateCreated datePublished" datetime="2020-01-21T14:08:27+08:00">2020-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="关于几种降维算法"><a href="#关于几种降维算法" class="headerlink" title="关于几种降维算法"></a>关于几种降维算法</h3><p>写一下几种主要降维算法的基本原理和实现 </p>
<ol>
<li><p>PCA(Principle Component Analysis) </p>
<p>PCA是最常见的一种降维算法，其核心思想是数据从高维到低维的投影，使其方差最大化。这个也很好理解，比如，这里我们假设有3组数据$a_1,a_2,a_3$，然后第1组的值可以用第2组数据的函数表示，比如$a_2=2*a_1$。如果以$a_1,a_2,a_3$为坐标画出对应的图像，那么在3维空间中就对应了一个平面，以这个平面的坐标轴为参数，此时看到的就是二维数据，相当于降维了。</p>
<p>插图（参考文献） ![dimensionality reduction-1](/img/dimensionality reduction-1.png)</p>
<p>参考文献： </p>
<p>假设我们有$m$组$n$维数据，希望能降维到$k$维($k&lt;d$)，PCA的计算过程如下： </p>
<p>数据零均值化</p>
<p>求协方差矩阵</p>
<p>求协方差矩阵对应的特征值和特征向量</p>
<p>将特征向量按特征值大小取前$k$行从上向下组成矩阵 </p>
<p>将得到的矩阵乘以$X$就能得到降维后的数据 </p>
<p>这里数据零均值化主要是为了方便后面的计算（测试一下不做这一步有什么问题） </p>
<p>然后求协方差矩阵，之所以选择协方差矩阵，是因为协方差能很好地反应不同维度之间的差异，假设数据集为$X={x_1,x_2,…,x_m}\in R^{m*n}$，</p>
<p>那么协方差矩阵$Cov$的定义为 </p>
<p>$$CovX(i,j)=\sum_{} x_ix_j\frac{1}{m}$$</p>
<p>因为之前做过零均值化，所以这里$x_i$和$x_j$的均值都是0。 可以看出，协方差矩阵非对角线上的值表示了不同维度上数据之间的差异，对角线上的数据表示了每个维度的数据分布的差异。即在所有组数据中，每个维度上的变化大小的评价。对于协方差矩阵，当$CovX(i,j)=0$时，说明第$i$维和第$j$维的数据是相互独立的，所以，PCA优化的目标在于，尽可能让不同维度之间的协方差为0，而尽可能增大维度自身的方差。 关于求协方差矩阵的特征值，可以理解为将一个特征向量在$n$维空间中进行旋转和拉伸变换，使之与特征向量自己在同一直线上并成一定的比例，那么这个变换就是这个矩阵（参考二维情况下，二维平面中对向量的拉伸和旋转都可以通过一个二阶方阵来实现，高维空间中同理），而这个比例就是特征值。在$n$维空间中，这样的特征向量最多有$n$个，这个可以参考特征向量的求法，当转换成方程组之后，$n$个方程组最多只能有$n$组解。关于为什么要求矩阵的特征值和特征向量，这是根据优化问题的解得到的。假设降维后的矩阵为$Y \in R^{m*k}$，转换矩阵为$T$，那么$Y$的协方差为</p>
<p>$$CovY=Y * Y^T * \frac{1}{m}$$</p>
<p>$$=(TY) * (TY)^T * \frac{1}{m}$$ </p>
<p>$$=T * CovX * T^T$$ </p>
<p>所以对于转换矩阵$T$，我们需要通过计算后，使得$CovY$为一个对角矩阵，并且矩阵中的值依次从大到小排列，因为根据优化的目标，我们需要使$CovY$的对角线上的值最大，且除对角线以外的数都为0。我们知道，实对称矩阵的不同特征向量是正交的。所以将$CovX$进行特征分解求出特征值和特征向量，然后取前$k$组特征向量组成转换矩阵$T$，就可以使得降维后的矩阵$Y$的维度与维度之间的差异值最大。 关于代码和计算，matlab中有princomp和pca函数可以直接计算。 这里数据用的是鸢尾花数据集， 代码如下： </p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">load fixeddata; </span><br><span class="line">[coeff,score,latent] = pca(newdata); </span><br><span class="line">result=score(:,<span class="number">1</span>:<span class="number">2</span>); </span><br><span class="line">x=result(:,<span class="number">1</span>); </span><br><span class="line">y=result(:,<span class="number">2</span>); </span><br><span class="line"><span class="built_in">scatter</span>(x,y,<span class="string">&#x27;x&#x27;</span>); </span><br></pre></td></tr></table></figure>

<p>结果如图：</p>
<p>![result of PCA](/img/dimensionality reduction-2.png)</p>
<p>综上，PCA是一种很常用的降维方法，也是一种无监督的降维方法。同时，从PCA的原理中可以看出，PCA对于线性相关的降维效果会比较好，但是对于非线性的数据，其降维效果可能就会差很多。 </p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/Deep-Leaning-Using-Matlab/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/Deep-Leaning-Using-Matlab/" class="post-title-link" itemprop="url">Deep Leaning Using Matlab</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2020-01-21 14:05:15" itemprop="dateCreated datePublished" datetime="2020-01-21T14:05:15+08:00">2020-01-21</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2020-04-08 16:57:42" itemprop="dateModified" datetime="2020-04-08T16:57:42+08:00">2020-04-08</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h3><ol>
<li><p>常见的matlab搭建神经网络的代码结构</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">options = trainingOptions(solverName, Name, Value);</span><br><span class="line">layer = [layer1, layer2];</span><br><span class="line">net = trainNetwork(TrainX, TrainY, options, layers);</span><br></pre></td></tr></table></figure>

<p>其中，trainingOptions的主要作用就是设置网络中的一些参数，主要包括以下参数：</p>
<table>
<thead>
<tr>
<th>参数名称</th>
<th>参数值</th>
<th>参数含义</th>
</tr>
</thead>
<tbody><tr>
<td>solverName</td>
<td>‘sgdm’|’rmsprop’|’adam’</td>
<td>优化方法</td>
</tr>
<tr>
<td>Plots</td>
<td>‘none’ | ‘training-progress’</td>
<td>是否画优化曲线</td>
</tr>
<tr>
<td>Verbose</td>
<td>1 | 0</td>
<td>是否显示优化信息，包括Loss，Epoch等信息</td>
</tr>
<tr>
<td>VerboseFrequency</td>
<td>int value</td>
<td>多长时间刷新一次信息，默认值是50</td>
</tr>
<tr>
<td>MaxEpochs</td>
<td>int value</td>
<td>最大循环次数，训练数据最多重复多少次</td>
</tr>
<tr>
<td>MiniBatchSize</td>
<td>int value</td>
<td>最小的batch size，每次训练的最小数据量</td>
</tr>
<tr>
<td>‘Shuffle’</td>
<td>’once‘ | ‘never’ | ‘every-epoch’</td>
<td>每个epoch是否重新排序训练数据</td>
</tr>
<tr>
<td>‘ValidationData’</td>
<td>imageData，Data Store, Table，Cell array{X, Y}</td>
<td>用来验证网络的数据，一般用cell</td>
</tr>
<tr>
<td>‘ValidationFrequency’</td>
<td>int value</td>
<td>迭代多少次验证一次</td>
</tr>
<tr>
<td>’ValidationPatience’</td>
<td>int value</td>
<td>如果这次的验证loss比上一次大，这种情况出现的次数超过这个值，那么停止网络训练</td>
</tr>
<tr>
<td>‘InitialLearnRate’</td>
<td>scalar</td>
<td>初始学习率</td>
</tr>
<tr>
<td>‘LearnRateSchedule’</td>
<td>‘none’|’piecewise’</td>
<td>调整学习率下降的方法，’piecewise‘方法会隔特定数目的epoch(LearnRateDropPeriod)就将LearnRate乘以一个factor(LearRateDropFactor)</td>
</tr>
<tr>
<td>’LearnRateDropPeriod’</td>
<td>int value</td>
<td>隔特定数目的epoch调整一次LearnRate</td>
</tr>
<tr>
<td>‘LearnRateDropFactor’</td>
<td>scalar(0-1)</td>
<td>每次LearnRate调整时乘以的因子</td>
</tr>
<tr>
<td>‘L2Regularization’</td>
<td>nonnegative scalar</td>
<td>用来减少过拟合，（需要继续学习）</td>
</tr>
<tr>
<td>’Momentum’</td>
<td>scalar(0-1)</td>
<td>动量，sgdm中前一次迭代中的参数在下一次迭代中所占的比例</td>
</tr>
<tr>
<td>‘GradientDecayFactor’</td>
<td>scalar(0-1)</td>
<td>adam方法中梯度值降低的平均值</td>
</tr>
<tr>
<td>’SquaredGradientDecayFactor‘</td>
<td>nonnegative scalar less than 1</td>
<td>梯度平方降低的平均值（Adam， RMSProp）</td>
</tr>
<tr>
<td>’Epsilon‘</td>
<td>int value</td>
<td>分母的偏置值(Adam, RMSProp)</td>
</tr>
<tr>
<td>‘ResetInputNormalization’</td>
<td>true | false</td>
<td>每次训练都将输入值标准化</td>
</tr>
<tr>
<td>’GradientThreshold‘</td>
<td>int value</td>
<td>梯度的阈值</td>
</tr>
<tr>
<td>’GradientThresholdMethod‘</td>
<td>’l2norm‘|’global-l2norm’|’absolute-value’</td>
<td>梯度阈值的计算方法</td>
</tr>
<tr>
<td>’SequenceLength‘</td>
<td>‘longest’|’shortest’|int value</td>
<td>输入的序列长度</td>
</tr>
<tr>
<td>’SequencePaddingDirection‘</td>
<td>’right’|’left’</td>
<td>如果序列需要截取，截取的方向</td>
</tr>
<tr>
<td>‘SequencePaddingValue’</td>
<td>int value</td>
<td>填充到序列中的值，用来补充数据长度</td>
</tr>
<tr>
<td>‘ExecutionEnvironment’</td>
<td>‘auto’|’cpu’|’gpu’|’multi-gpu’|’parallel’</td>
<td>选择硬件</td>
</tr>
<tr>
<td>‘WorkLoad’</td>
<td>scalar(0-1)|int|vector</td>
<td>GPU或CPU的负载，用到的核心数，以及并行计算时的负载</td>
</tr>
<tr>
<td>‘DispatchInBackground’</td>
<td>false | true</td>
<td>后台拆分数据并分配核心同时读取</td>
</tr>
<tr>
<td>‘CheckpointPath’</td>
<td>character</td>
<td>存放网络训练中间值的路径</td>
</tr>
<tr>
<td>‘OutputFunc’</td>
<td>function handle</td>
<td>网络训练时，trainNetwork函数会在刚开始训练时，每次迭代结束时，训练结束时调用这个函数</td>
</tr>
</tbody></table>
<p>trainingOptions函数主要用来设置网络训练过程中的参数，需要熟悉其中的参数的作用</p>
<p>layers主要表示网络的结构，层与层之间的连接等，其中主要包括各种网络层，目前常用的有如下几类：</p>
<table>
<thead>
<tr>
<th>网络层</th>
<th>参数</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td>allLayer</td>
<td>Name</td>
<td>网络层的名称</td>
</tr>
<tr>
<td></td>
<td>NumInputs</td>
<td>输入的个数</td>
</tr>
<tr>
<td></td>
<td>InputNames</td>
<td>输入数据的名称，cell</td>
</tr>
<tr>
<td></td>
<td>NumOutputs</td>
<td>输出的个数</td>
</tr>
<tr>
<td></td>
<td>OutputNames</td>
<td>输出数据的名称，cell</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>sequenceLayer</td>
<td>InputSize</td>
<td>输入序列的大小，如果是图像的话，那么就是一个三维或四维矩阵</td>
</tr>
<tr>
<td></td>
<td>Normalization</td>
<td>数据归一化的方法选择</td>
</tr>
<tr>
<td></td>
<td>NormalizationDimension</td>
<td>归一化的维度，按照通道，按照元素或者全部统一</td>
</tr>
<tr>
<td></td>
<td>Mean</td>
<td>设置数据的均值配合zscore和zerocenter等归一化方法使用</td>
</tr>
<tr>
<td></td>
<td>StandardDeviation</td>
<td>标准差，配合对应的归一化方法使用</td>
</tr>
<tr>
<td></td>
<td>Min</td>
<td>归一化后的最小值</td>
</tr>
<tr>
<td></td>
<td>Max</td>
<td>归一化后的最大值</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>fullyConnectedLayer</td>
<td>OutputSize</td>
<td>输出层大小</td>
</tr>
<tr>
<td></td>
<td>InputSize</td>
<td>输入层大小</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2020/01/21/C-Sharp-Notes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2020/01/21/C-Sharp-Notes/" class="post-title-link" itemprop="url">C Sharp Notes</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2020-01-21 14:05:01 / Modified: 14:20:18" itemprop="dateCreated datePublished" datetime="2020-01-21T14:05:01+08:00">2020-01-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BC%96%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">编程</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="C-语法相关"><a href="#C-语法相关" class="headerlink" title="C#语法相关"></a>C#语法相关</h3><ol>
<li><p>Lambda表达式</p>
<p>委托的另一种表达方式</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">delegate</span> <span class="title">NumberChange</span>(<span class="params"><span class="built_in">int</span> Funcn</span>)</span>;</span><br><span class="line">NumberChange nc1 = (Funcn) =&gt; Funcn + <span class="number">10</span>; <span class="comment">// =&gt;读作 goes to</span></span><br></pre></td></tr></table></figure></li>
<li><p>委托(delegate)</p>
<ol>
<li><p>委托有点类似C++中的函数指针，其参数可以是一个函数，例如:</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">deletate <span class="built_in">int</span> <span class="title">NumberChange</span>(<span class="params"><span class="built_in">int</span> Funcn</span>)</span>;</span><br></pre></td></tr></table></figure>

<p>定义中，Func是一个返回int类型的函数</p>
</li>
<li><p>委托的多播(multicasting)</p>
<p>多个相同类型的委托可以合并，例如：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">delegate</span> <span class="built_in">int</span> <span class="title">NumberChange</span>(<span class="params"><span class="built_in">int</span> Funcn</span>)</span>;</span><br><span class="line">NumberChange nc;</span><br><span class="line">NumberChange nc1 = <span class="keyword">new</span> NumberChange(AddNum); <span class="comment">//AddNum是一个函数，返回int</span></span><br><span class="line">NumberChange nc2 = <span class="keyword">new</span> NumberChange(MultiNum); <span class="comment">// MultiNum是一个函数，返回int</span></span><br><span class="line">nc = nc1 + nc2;</span><br></pre></td></tr></table></figure></li>
<li><p>委托的实例化不带有任何参数</p>
</li>
<li><p>匿名委托</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="built_in">delegate</span> <span class="built_in">int</span> <span class="title">NumberChange</span>(<span class="params"><span class="built_in">int</span> FUncn</span>)</span>;</span><br><span class="line">NumberChange nc1 = <span class="built_in">delegate</span>(<span class="built_in">int</span> Funcn);</span><br><span class="line">&#123;</span><br><span class="line">	<span class="comment">//实现AddNum的功能</span></span><br><span class="line">	<span class="keyword">return</span> Funcn + <span class="number">10</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
<li><p>泛型委托</p>
<p>委托函数参数类型有多种，但是返回参数类型是最后一个</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Func&lt;<span class="built_in">int</span>, <span class="built_in">int</span>, <span class="built_in">bool</span>&gt; gwl = (p, j) =&gt;</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">if</span>(p+j==<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line">Console.WriteLine(gwl(<span class="number">5</span>, <span class="number">5</span>) + <span class="string">&quot;&quot;</span>);</span><br><span class="line">Console.ReadKey();</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
<li><p>sealed关键字</p>
<ol>
<li><p>类似于Java中的final关键字，sealed修饰的类不能被继承</p>
<p>  ​    </p>
</li>
</ol>
</li>
<li><p>list<T> 的用法</p>
<ol>
<li><p>泛型list，和泛型委托的概念类似，其定义为：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">List&lt;T&gt; testList = <span class="keyword">new</span> List&lt;T&gt;(IEnumerable&lt;T&gt; Collection);</span><br><span class="line"><span class="comment">// e.g</span></span><br><span class="line"><span class="built_in">string</span>[] temArr = &#123;<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;D&quot;</span>&#125;;</span><br><span class="line">List&lt;<span class="built_in">string</span>&gt; testList = <span class="keyword">new</span> List&lt;<span class="built_in">string</span>&gt;(tempArr);</span><br><span class="line"><span class="comment">//或者这么写</span></span><br><span class="line">List&lt;<span class="built_in">string</span>&gt; testList = <span class="keyword">new</span> List&lt;<span class="built_in">string</span>&gt;&#123;<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;C&quot;</span>&#125;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>和C++中的vector动态数组有点类似</p>
</li>
<li><p>list的主要函数也和vector比较类似，例如：</p>
<figure class="highlight c#"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">List.Add(T item);<span class="comment">//添加单个元素</span></span><br><span class="line">List.AddRange(IEnumerable&lt;T&gt; collection);<span class="comment">//添加一组元素</span></span><br><span class="line">List.Insert(<span class="built_in">int</span> index, T item); <span class="comment">//在index处添加元素item</span></span><br><span class="line">List.Remove(T item);<span class="comment">//移除元素item</span></span><br><span class="line">List.RemveAt(<span class="built_in">int</span> index);<span class="comment">//移除index处的元素</span></span><br><span class="line">List.RemoveRange(<span class="built_in">int</span> index, <span class="built_in">int</span> count);<span class="comment">//移除index处开始的count个元素</span></span><br><span class="line">List.Contains(T item);<span class="comment">//判断是否包含元素item</span></span><br><span class="line">List.Sort();<span class="comment">//List排序</span></span><br><span class="line">List.Reverse();<span class="comment">//翻转List</span></span><br><span class="line">List.Clear();<span class="comment">//清除List</span></span><br><span class="line">List.Count();<span class="comment">//计算List中元素的个数</span></span><br><span class="line">List.Find(Predicate&lt;T&gt; match);<span class="comment">//搜索List中满足条件的元素，并返回第一个元素</span></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://frankmartinem.github.io/2019/11/03/Kalman/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/portrait.jpg">
      <meta itemprop="name" content="Frank">
      <meta itemprop="description" content="Stay Hungry, Stay Foolish">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="FrankMartinem Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/11/03/Kalman/" class="post-title-link" itemprop="url">Kalman</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-11-03 15:46:44" itemprop="dateCreated datePublished" datetime="2019-11-03T15:46:44+08:00">2019-11-03</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">Edited on</span>
        <time title="Modified: 2021-04-12 16:06:56" itemprop="dateModified" datetime="2021-04-12T16:06:56+08:00">2021-04-12</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AE%97%E6%B3%95/" itemprop="url" rel="index"><span itemprop="name">算法</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="Kalman-Filter"><a href="#Kalman-Filter" class="headerlink" title="Kalman Filter"></a>Kalman Filter</h2><p>本文简单介绍了卡尔曼滤波(Kalman Filter)的基本原理以及我对卡尔曼滤波的一些理解。</p>
<h5 id="首先谈一下我的一点点理解"><a href="#首先谈一下我的一点点理解" class="headerlink" title="首先谈一下我的一点点理解"></a>首先谈一下我的一点点理解</h5><p>卡尔曼滤波是目前应用很广泛的一种滤波方法，最早由Kalman老先生在1960年提出，网上可以找到原文。这种方法最开始用在航天领域，作为轨道矫正的一种方法，有很好的效果。</p>
<p>卡尔曼滤波的方法的核心思想，就是用另一个测量空间的观测值去纠正当前空间对被测量的量的估计。简单来说，就是用一种方法去测量一个量。同时建立一个模型去估计这个测量的量，最后，按权重的方式求这两种方式的和，就是滤波之后的量的值。而这个权重的大小，就是卡尔曼系数。</p>
<h5 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h5><p>首先，我们假设要测量的量为$x$, 这个量有一个模型去描述其随时间的变化，例如计算每天的温度变化，可以大致根据之前几天的温度变化规律得到一个计算矩阵，这里也有一个计算模型去计算这个变量$x$</p>
<p>$$x_t=Fx_{t-1} + w_t$$ </p>
<p>$$w_{t} - N(0,Q)$$ </p>
<p>其中$F$为转换矩阵，$w_{t-1}$表示$t-1$时刻的噪声，且该噪声服从高斯分布。在其他的卡尔曼滤波公式推导中，会有一个额外的控制量，这里不考虑这个量。</p>
<p>对于测量矩阵，也有一个公式去转换。例如测量温度可以用温度传感器来测量，但是温度传感器的测量是因为温度改变了电阻的阻值，所以根据电压电流以及电阻随温度的变化曲线而计算出来的。在卡尔曼模型中，这一公式可以表示为如下等式</p>
<p>$$z_t=Hx_t+v_t$$ </p>
<p>$v_t - N(0,R)$</p>
<p>其中，$z_t$是通过测量的量，对应到上述的例子中，就是温度传感器的电阻阻值，$x_t$就是温度。$H$是测量矩阵，用来将测量的量转换成要估计的量。$v_t$是测量过程中存在的误差。同样的，$v_t$也是服从高斯分布的白噪声。</p>
<p>然后就是卡尔曼滤波的核心思想了，有了这两种方法得到的$x_t$，那么怎么得到一个更准确的估计值。所以需要将两种方法得到的估计值进行算一下加权平均，就得到了最优的估计值。所以卡尔曼滤波的方法如下：</p>
<ol>
<li><p>首先根据模型计算当前时刻的估计值<br>$$<br>x_t’=Fx_{t-1} + w_t<br>$$</p>
</li>
<li><p>然后根据测量矩阵计算当前的测量值的估计值</p>
</li>
</ol>
<p>$$<br>z_t’=Hx_t’+v_t<br>$$</p>
<ol start="3">
<li>然后计算测量值和测量估计值之间的差，并以此作为对最终估计值的调整。从这里可以看出，如果$x_t’$估计的很准，就是说此时$z_t$的值和$z_t’$的值相差很小，那么$z_t$对于$x_t$的修正也就越少。但是如果估计值和测量值相差很大，那么$z_t$对$x_t$的修正也就越大。其中，$K_t$是卡尔曼增益，表示滤波器对测量值的信任程度。</li>
</ol>
<p>$$<br>x_t=x_t’+K_t*(z_t-z_t’)<br>$$</p>
<p>那么如何估计卡尔曼增益，可以用贝叶斯估计的方法推导，也可以用最小二乘法的方式推导，这里用最小二乘法的方式推导</p>
<p>我们假设真实值是$X_t$，那么卡尔曼滤波计算得到的估计值和真实值之间的协方差</p>
<p>$$<br>P(x_t|X_t)= E[(X_t-x_t)(X_t-x_t)^T]<br>$$</p>
<p>卡尔曼滤波的估计值和模型的估计值之间的协方差，用来评估两种估计的差别</p>
<p>$$<br>P(x|x’)=E[(x_t-x_t’)(x_t-x_t’)^T]<br>$$</p>
<p>根据卡尔曼的估计公式以及测量公式，可以得到</p>
<p>$$<br>P(x_t|X_t)=E [(X_t - x_t’ - K_t * ( z_t - z_t’)) ( X_t - x_t’ - K_t * ( z_t - z_t’ ))^T]<br>$$</p>
<p>$$<br>=E[((I-K_tH)(X_t-x_t’)-K_tv_t)((I-K_tH)(X_t-x_t’)-K_tv_t)^T]<br>$$</p>
<p>把上述等式展开，可以得到<br>$$<br>P(x_t|X_t)=(I-K_tH)P(x_t|x_t’)(I-K_tH)+K_tE[v_tv_t^T]K_t^T<br>$$</p>
<p>$$<br>=P(x_t|x_t’)-K_tHP(x_t|x_t’)-P(x_t|x_t’)H^TK_t^T+K_t(HP(x_t|x_t’)H^T+R)K_t^T<br>$$</p>
<p>所以，如果我们要估计的更准确，那么就要$P(x_t|X_t)$更小，就是说真实值和卡尔曼滤波的估计值之间的协方差最小。不考虑估计值之间的相关，那么协方差矩阵的对角线元素就表示了卡尔曼估计值和真实值之间的方差。接下来就是求方差最小的情况下对应的卡尔曼增益$K_t$。可以用矩阵的迹的方法求解<br>$$<br>tr(P(x_t|X_t)) = tr(P(x_t|x_t’))-2tr(K_tHP(x_t|x_t’))+tr(K_t(HP(x_t|x_t’)H^T+R)K_t^T)<br>$$</p>
<p>可以看出，$tr(P(x_t|X_t))$是$K_t$的二次函数，所以根据二次函数求极值的方法，对tr(P(x_t|X_t))求导，得到</p>
<p>$$<br>\frac{d(tr(P(x_t|X_t)))}{d(K_t)}=-2(HP(x_t|x_t’))^T+2K_t(HP(x_t|x_t’)H^T+R)<br>$$</p>
<p>令$\frac{d(tr(P(x_t|X_t)))}{d(K_t)}=0$，所以有</p>
<p>$$<br>K_t=P(x_t|x_t’)H^T(HP(x_t|x_t’)H^T+R)^{-1}<br>$$</p>
<p>把$K_t$的结果带入到$P(x_t|X_t)$的表达式中，有</p>
<p>$$<br>P(x_t|X_t)=P(x_t|x_t’)-K_tHP(x_t|x_t’)-P(x_t|x_t’)H^TK_t^T+K_t(HP(x_t|x_t’)H^T+R)K_t^T<br>$$</p>
<p>$$<br>=P(x_t|x_t’)-K_tHP(x_t|x_t’)-\frac{HP(x_t|x_t’)^TP(x_t|x_t’)H^T}{HP(x_t|x_t’)H^T+R}+\frac{HP(x_t|x_t’)^TP(x_t|x_t’)H^T}{HP(x_t|x_t’)H^T+R}<br>$$</p>
<p>$$<br>=P(x_t|x_t’)-K_tHP(x_t|x_t’)<br>=(I-K_tH)P(x_t|x_t’)<br>$$</p>
<p>所以根据上述的推导计算，可以得到卡尔曼滤波的计算过程：</p>
<ol>
<li>首先，根据已知的模型，以及上一时刻的卡尔曼估计值，计算当前时刻的模型预测值</li>
</ol>
<p>$$<br>x_t’=Fx_{t-1}<br>$$</p>
<ol start="2">
<li>根据当前的模型预测值，计算对应的协方差</li>
</ol>
<p>$$<br>P(x_t|x_t’)=FP(x_t|X_t)F^T<br>$$</p>
<ol start="3">
<li>根据当前的协方差和测量空间的转换矩阵，计算当前时刻的卡尔曼增益</li>
</ol>
<p>$$<br>K_t=P(x_t|x_t’)H^T(HP(x_t|x_t’)H^T+R)^{-1}<br>$$</p>
<ol start="4">
<li>根据卡尔曼增益和测量值，计算当前时刻的卡尔曼估计值</li>
</ol>
<p>$$<br>x_t=x_t’+K_t(z_t-Hx_t’)<br>$$</p>
<ol start="5">
<li>计算了当前时刻的卡尔曼估计值之后，还需要计算当前的估计值和真实值的协方差矩阵，方便下一次计算</li>
</ol>
<p>$$<br>P(x_t|X_t)=(I-HK_t)P(x_t|x_t’)<br>$$</p>
<p>以上就是卡尔曼滤波的基本过程，以及一些简单的推导。总体上说理解卡尔曼滤波应该算一种最优估计的算法。也是应用很广泛的，然后卡尔曼滤波的推导方法也有很多，除了最小二乘法，也可以从贝叶斯估计的角度推导。两者是类似的。</p>
<h5 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h5>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>
<script src="/js/comments.js"></script>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Frank</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{&quot;enable&quot;:true,&quot;tags&quot;:&quot;none&quot;,&quot;js&quot;:&quot;https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;mathjax@3.1.2&#x2F;es5&#x2F;tex-mml-chtml.js&quot;}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
